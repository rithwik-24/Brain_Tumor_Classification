# import streamlit as st
# import tensorflow as tf
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing import image
# import numpy as np
# import plotly.graph_objects as go
# import cv2
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense, Dropout, Flatten
# from tensorflow.keras.optimizers import Adamax
# from tensorflow.keras.metrics import Precision, Recall
# import google.generativeai as genai # gemini model to generate explanations of the brain scans
# import PIL.Image
# import os
# from dotenv import load_dotenv
# import gdown
# load_dotenv()

# # Support both local .env and Streamlit Cloud secrets
# try:
#     api_key = st.secrets["GOOGLE_API_KEY"]
# except:
#     api_key = os.getenv("GOOGLE_API_KEY")

# if api_key:
#     genai.configure(api_key=api_key)

# # Model download configuration
# MODEL_FILES = {
#     'cnn_model.h5': {
#         'path': 'models/cnn_model.h5',
#         'url': 'https://drive.google.com/uc?id=1-zvRYokb7WQF4QGZOpndgGKHWsEYUvfu'
#     },
#     'xception_model.weights.h5': {
#         'path': 'models/xception_model.weights.h5',
#         'url': 'https://drive.google.com/uc?id=1_O5VFfubbaoPd7HCwqziKt1UqnDx0zxK'
#     }
# }

# def download_model_if_needed(model_name):
#     """Download model from Google Drive if it doesn't exist locally"""
#     model_info = MODEL_FILES[model_name]
#     model_path = model_info['path']

#     if not os.path.exists(model_path):
#         st.info(f"Downloading {model_name} (first time only)... This may take a few minutes.")
#         os.makedirs('models', exist_ok=True)
#         gdown.download(model_info['url'], model_path, quiet=False)
#         st.success(f"{model_name} downloaded successfully!")

#     return model_path

# # saliency maps is the directory where we store the saliency images

# output_dir = 'saliency_maps'
# os.makedirs(output_dir, exist_ok=True)


# def generate_explanation(img_path, model_prediction, confidence):
#     prompt = f"""You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.
#     The saliency map was generated by a deep learning model that was trained to classify brain tumors
#     as either glioma, meningioma, pituitary, or no tumor.

#     The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.

#     The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.
    
#     In your response:
#     - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted in light cyan, those are the regions where the model is focusing on.
#     - Explain possible reasons why the model made the prediction it did.
#     - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan' in your explanation.
#     - Keep your explanation to 4 sentences max.
#     """

#     img = PIL.Image.open(img_path)

#     model = genai.GenerativeModel(model_name="gemini-2.0-flash-exp")
#     response = model.generate_content([prompt, img])

#     return response.text



# # saliency shows which pixels in the image were the most important to deduce the conclusion

# def generate_saliency_map(model, img_array, class_index, img_size, img, uploaded_file, file_name):
#     with tf.GradientTape() as tape:
#         img_tensor = tf.convert_to_tensor(img_array)
#         tape.watch(img_tensor)
#         predictions = model(img_tensor)
#         target_class = predictions[0, class_index]

#     gradients = tape.gradient(target_class, img_tensor)
#     gradients = tf.math.abs(gradients)
#     gradients = tf.reduce_max(gradients, axis=-1)
#     gradients = gradients.numpy().squeeze()

#     # Resize gradients to match original image size
#     gradients = cv2.resize(gradients, img_size)

#     # Create a circular mask for the brain area
#     center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
#     radius = min(center[0], center[1]) - 10
#     x, y = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
#     mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

#     # Apply mask to gradients
#     gradients = gradients * mask

#     # Normalize only the brain area
#     brain_gradients = gradients[mask]
#     if brain_gradients.max() > brain_gradients.min():
#         brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
#         gradients[mask] = brain_gradients

#     # Apply a higher threshold
#     threshold = np.percentile(gradients[mask], 80)
#     gradients[gradients < threshold] = 0

#     # Apply more aggressive smoothing
#     gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

#     # Create a heatmap overlay with enhanced contrast
#     heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
#     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

#     # Resize heatmap to match original image size
#     heatmap = cv2.resize(heatmap, img_size)

#     # Superimpose the heatmap on the original image with increased opacity
#     original_img = image.img_to_array(img)
#     superimposed_img = heatmap * 0.7 + original_img * 0.3
#     superimposed_img = superimposed_img.astype(np.uint8)

#     # Save original image for AI explanation
#     img_path = os.path.join(output_dir, file_name)
#     if isinstance(uploaded_file, str):
#         # It's a sample image path, copy it
#         import shutil
#         shutil.copy(uploaded_file, img_path)
#     else:
#         # It's an uploaded file object
#         with open(img_path, "wb") as f:
#             f.write(uploaded_file.getbuffer())

#     saliency_map_path = f'saliency_maps/{file_name}'

#     # Save the saliency map
#     cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

#     return superimposed_img


# # use the load_xcception_model part of its package
# # for cnn we use the load_model from streamlit or tensorflow

# def load_xception_model(model_path):
#     img_shape = (299, 299, 3)
#     base_model = tf.keras.applications.Xception(
#         include_top=False,
#         weights="imagenet",
#         input_shape=img_shape,
#         pooling="max"
#     )

#     model = Sequential([
#         base_model,
#         Flatten(),
#         Dropout(rate=0.3),
#         Dense(128, activation='relu'),
#         Dropout(rate=0.25),
#         Dense(4, activation='softmax')
#     ])

#     model.build((None,) + img_shape)

#     # Compile the model
#     model.compile(
#         Adamax(learning_rate=0.001),
#         loss='categorical_crossentropy',
#         metrics=['accuracy', Precision(), Recall()]
#     )

#     model.load_weights(model_path)
#     return model


# st.title("Brain Tumor Classification")
# st.write("Upload an image of a brain MRI scan to classify.")

# # Sample images section
# st.write("### Try with sample images:")

# sample_images = {
#     'Glioma': 'sample_data/Glioma.png',
#     'Meningioma': 'sample_data/Meningioma.png',
#     'No Tumor': 'sample_data/NoTumor.png',
#     'Pituitary': 'sample_data/Pituitary.png'
# }

# # Initialize session state for selected sample
# if 'selected_sample' not in st.session_state:
#     st.session_state.selected_sample = None

# # Create equal-width columns with uniform spacing
# col1, col2, col3, col4 = st.columns(4, gap="small")

# # Display images
# columns = [col1, col2, col3, col4]
# sample_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']

# for col, name in zip(columns, sample_names):
#     with col:
#         # Display image with container width for uniform sizing
#         st.image(sample_images[name], use_container_width=True)
#         st.caption(name)
#         if st.button(f'Use {name} Sample', key=f'btn_{name}', use_container_width=True):
#             st.session_state.selected_sample = sample_images[name]

# st.write("### Or upload your own image:")
# uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

# # Use sample if selected, otherwise use uploaded file
# if st.session_state.selected_sample is not None:
#     uploaded_file = st.session_state.selected_sample
#     st.info(f"Using sample image: {os.path.basename(uploaded_file)}")
#     # Reset after use
#     if st.button("Clear sample selection"):
#         st.session_state.selected_sample = None
#         st.rerun()

# # the user has uploaded an image for scanning we want to give them the choice to choose between
# # the transfer learning model using xception
# # the custom onvolutional neural network model

# if uploaded_file is not None:
#     selected_model = st.radio(
#         "Select Model",
#         ("Transfer Learning - Xception" ,"Custom CNN")
#     )

#     if selected_model == "Transfer Learning - Xception":
#         model_path = download_model_if_needed('xception_model.weights.h5')
#         model = load_xception_model(model_path)
#         img_size = (299,299)
#     else:
#         model_path = download_model_if_needed('cnn_model.h5')
#         model = load_model(model_path)
#         img_size = (224,224)

#     labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']

#     # Handle both file upload and sample image path
#     if isinstance(uploaded_file, str):
#         # It's a sample image path
#         img = image.load_img(uploaded_file, target_size=img_size)
#         file_name = os.path.basename(uploaded_file)
#     else:
#         # It's an uploaded file object
#         img = image.load_img(uploaded_file, target_size=img_size)
#         file_name = uploaded_file.name
#     img_array = image.img_to_array(img)
#     img_array = np.expand_dims(img_array, axis=0)
#     img_array /= 255.0

#     prediction = model.predict(img_array)

#     # Get the class with the highest probability
#     class_index = np.argmax(prediction[0])
#     result = labels[class_index]

#     st.write(f"Predicted Class: {result}")
#     st.write("Predictions:")
#     for label, prob in zip(labels, prediction[0]):
#         st.write(f"{label}: {prob:.4f}")

#     saliency_map = generate_saliency_map(model, img_array, class_index, img_size, img, uploaded_file, file_name)

#     col1, col2 = st.columns(2)
#     with col1:
#         st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)
#     with col2:
#         st.image(saliency_map, caption='Saliency Map', use_container_width=True)

#     saliency_map_path = f'saliency_maps/{file_name}'
#     explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])

#     st.write("## Explanation")
#     st.write(explanation)


# def generate_explanation(result, confidence):
#     explanations = {
#         "Glioma": "Diffuse infiltrative regions detected.",
#         "Meningioma": "Well-circumscribed tumor near brain surface.",
#         "Pituitary": "Localized activity near pituitary gland.",
#         "No tumor": "Normal brain anatomy detected."
#     }
#     return f"{explanations[result]} Confidence: {confidence*100:.2f}%."



# import streamlit as st
# import tensorflow as tf
# import numpy as np
# import cv2
# import random
# import time
# import plotly.graph_objects as go
# import PIL.Image
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing import image

# # ===============================
# # CONFIG & STYLING
# # ===============================
# st.set_page_config(
#     page_title="Federated Brain AI",
#     layout="wide",
#     initial_sidebar_state="collapsed"
# )

# def apply_custom_css():
#     st.markdown("""
#         <style>
#         .stApp {
#             background: radial-gradient(circle at center, #102a43 0%, #050a0f 100%);
#             color: #E2E8F0;
#         }
#         .main-card {
#             background: rgba(15, 23, 42, 0.4);
#             border: 1px solid rgba(255, 255, 255, 0.1);
#             backdrop-filter: blur(12px);
#             border-radius: 15px;
#             padding: 25px;
#             margin-bottom: 20px;
#         }
#         .prediction-header {
#             background: rgba(0, 210, 255, 0.1);
#             border: 2px solid #00D2FF;
#             padding: 20px;
#             border-radius: 15px;
#             text-align: center;
#             margin-top: 20px;
#         }
#         .stButton>button {
#             width: 100%;
#             background: linear-gradient(90deg, #00D2FF 0%, #3A7BD5 100%);
#             color: white;
#             border: none;
#             padding: 12px;
#             border-radius: 8px;
#             font-weight: bold;
#         }
#         </style>
#     """, unsafe_allow_html=True)

# apply_custom_css()

# # ===============================
# # SESSION STATE
# # ===============================
# if "page" not in st.session_state:
#     st.session_state.page = "Landing"

# if "has_prediction" not in st.session_state:
#     st.session_state.has_prediction = False

# if "global_acc" not in st.session_state:
#     st.session_state.global_acc = random.uniform(83, 94)

# if "acc_history" not in st.session_state:
#     st.session_state.acc_history = [st.session_state.global_acc]

# # ===============================
# # UTILITIES
# # ===============================
# def generate_explanation(result, confidence):
#     explanations = {
#         "Glioma": "Diffuse infiltrative regions detected.",
#         "Meningioma": "Well-circumscribed tumor near brain surface.",
#         "Pituitary": "Localized activity near pituitary gland.",
#         "No tumor": "Normal brain anatomy detected."
#     }
#     return f"{explanations[result]} Confidence: {confidence*100:.2f}%."

# def generate_saliency_map(model, img_array, class_index, img_size, img):
#     with tf.GradientTape() as tape:
#         img_tensor = tf.convert_to_tensor(img_array)
#         tape.watch(img_tensor)
#         preds = model(img_tensor)
#         loss = preds[:, class_index]

#     grads = tape.gradient(loss, img_tensor)
#     grads = tf.reduce_max(tf.abs(grads), axis=-1).numpy()[0]
#     grads = cv2.resize(grads, img_size)
#     grads = (grads - grads.min()) / (grads.max() - grads.min() + 1e-8)
#     grads = cv2.GaussianBlur(grads, (11, 11), 0)

#     heatmap = cv2.applyColorMap(np.uint8(255 * grads), cv2.COLORMAP_JET)
#     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

#     original = image.img_to_array(img)
#     overlay = 0.65 * heatmap + 0.35 * original
#     return overlay.astype(np.uint8)

# # ===============================
# # LANDING PAGE
# # ===============================
# if st.session_state.page == "Landing":
#     st.markdown("<h1 style='text-align:center;'>üåê Federated Brain AI Portal</h1>", unsafe_allow_html=True)
#     c1, c2 = st.columns(2)

#     with c1:
#         st.markdown("""
#             <div class="main-card">
#             <h3>üß† Client Node</h3>
#             <p>Run private MRI predictions and generate saliency maps.</p>
#             </div>
#         """, unsafe_allow_html=True)
#         if st.button("Access Client Node"):
#             st.session_state.page = "Client"
#             st.rerun()

#     with c2:
#         st.markdown("""
#             <div class="main-card">
#             <h3>üåç Global Model</h3>
#             <p>Monitor accuracy and execute federated rounds.</p>
#             </div>
#         """, unsafe_allow_html=True)
#         if st.button("Access Global Model"):
#             st.session_state.page = "Global"
#             st.rerun()

# # ===============================
# # CLIENT PAGE
# # ===============================
# elif st.session_state.page == "Client":
#     if st.button("‚Üê Back to Portal"):
#         st.session_state.page = "Landing"
#         st.rerun()

#     st.title("üß† Local Client Node")

#     uploaded_file = st.file_uploader("Upload Brain MRI Scan", type=["jpg", "jpeg", "png"])

#     if uploaded_file:
#         model = load_model("models/cnn_model.h5")
#         labels = ["Glioma", "Meningioma", "No tumor", "Pituitary"]

#         img = image.load_img(uploaded_file, target_size=(224, 224))
#         img_array = image.img_to_array(img) / 255.0
#         img_array = np.expand_dims(img_array, axis=0)

#         preds = model.predict(img_array)
#         class_index = np.argmax(preds[0])
#         result = labels[class_index]
#         confidence = preds[0][class_index]

#         saliency = generate_saliency_map(model, img_array, class_index, (224, 224), img)

#         st.session_state.has_prediction = True

#         c1, c2 = st.columns(2)
#         with c1:
#             st.image(uploaded_file, caption="Uploaded MRI", use_container_width=True)
#         with c2:
#             st.image(saliency, caption="Saliency Map", use_container_width=True)

#         st.markdown(f"""
#             <div class="prediction-header">
#                 <h2>{result}</h2>
#                 <p>Confidence: {confidence*100:.2f}%</p>
#             </div>
#         """, unsafe_allow_html=True)

#         st.markdown("### Explanation")
#         st.write(generate_explanation(result, confidence))

#         st.markdown("### Training Logs")
#         st.code("""
# [INFO] Local epochs completed: 14
# [INFO] Gradient computation successful
# [INFO] Ready for federated aggregation
#         """)

# # ===============================
# # GLOBAL PAGE
# # ===============================
# elif st.session_state.page == "Global":
#     if st.button("‚Üê Back to Portal"):
#         st.session_state.page = "Landing"
#         st.rerun()

#     st.title("üåç Global Model Server")

#     m1, m2 = st.columns(2)
#     m1.metric("Global Accuracy", f"{st.session_state.global_acc:.2f}%")
#     m2.metric("Predictions Received", "‚â•1" if st.session_state.has_prediction else "0")

#     fig = go.Figure()
#     fig.add_trace(go.Scatter(
#         y=st.session_state.acc_history,
#         mode="lines+markers"
#     ))
#     fig.update_layout(
#         height=300,
#         template="plotly_dark",
#         yaxis_range=[80, 100]
#     )
#     st.plotly_chart(fig, use_container_width=True)

#     st.markdown("<div class='main-card'>", unsafe_allow_html=True)

#     if st.button(
#         "üöÄ Start Federated Round",
#         disabled=not st.session_state.has_prediction
#     ):
#         with st.spinner("Aggregating client updates..."):
#             time.sleep(2)
#             new_acc = random.uniform(83, 94)
#             st.session_state.global_acc = new_acc
#             st.session_state.acc_history.append(new_acc)
#             st.success("Federated round completed")

#     if not st.session_state.has_prediction:
#         st.warning("Run at least one client prediction to enable aggregation.")

#     st.markdown("</div>", unsafe_allow_html=True)

import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
import random
import time
import os
import json
import plotly.graph_objects as go
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax

# ===============================
# CONFIG
# ===============================
st.set_page_config(
    page_title="Federated Medical AI",
    layout="wide",
    initial_sidebar_state="collapsed"
)

GLOBAL_MIN = 65.0
GLOBAL_MAX = 87.0
AGGREGATION_THRESHOLD = 70.0
GLOBAL_HISTORY_FILE = "global_accuracy_history.json"

CLASS_NAMES = ["Glioma", "Meningioma", "Pituitary", "No Tumor"]

output_dir = "saliency_maps"
os.makedirs(output_dir, exist_ok=True)

# ===============================
# BACKGROUND STYLE
# ===============================
st.markdown("""
<style>
.stApp {
    background:
      radial-gradient(circle at 20% 20%, rgba(0,210,255,0.15), transparent 40%),
      radial-gradient(circle at 80% 30%, rgba(58,123,213,0.12), transparent 45%),
      radial-gradient(circle at 50% 80%, rgba(0,255,180,0.10), transparent 50%),
      #050a0f;
    color: #E2E8F0;
}
.glass {
    background: rgba(15, 23, 42, 0.45);
    backdrop-filter: blur(14px);
    border-radius: 16px;
    padding: 20px;
}
.stButton>button {
    width: 100%;
    background: linear-gradient(90deg,#00D2FF,#3A7BD5);
    color: white;
    border-radius: 10px;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# ===============================
# SESSION STATE
# ===============================
if "page" not in st.session_state:
    st.session_state.page = "Landing"

if "acc_history" not in st.session_state:
    if os.path.exists(GLOBAL_HISTORY_FILE):
        with open(GLOBAL_HISTORY_FILE, "r") as f:
            try:
                st.session_state.acc_history = json.load(f)
            except:
                st.session_state.acc_history = []
    else:
        st.session_state.acc_history = []

    if len(st.session_state.acc_history) == 0:
        acc = round(random.uniform(80, 88), 2)
        st.session_state.acc_history = [acc]
        st.session_state.global_acc = acc
    else:
        st.session_state.global_acc = st.session_state.acc_history[-1]

if "has_integrated" not in st.session_state:
    st.session_state.has_integrated = False

# ===============================
# SALIENCY MAP
# ===============================
def generate_saliency_map(model, img_array, class_index, img_size, img, uploaded_file, file_name):
    with tf.GradientTape() as tape:
        img_tensor = tf.convert_to_tensor(img_array)
        tape.watch(img_tensor)
        predictions = model(img_tensor)
        target_class = predictions[0, class_index]

    gradients = tape.gradient(target_class, img_tensor)
    gradients = tf.reduce_max(tf.abs(gradients), axis=-1).numpy().squeeze()
    gradients = cv2.resize(gradients, img_size)

    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center) - 10
    x, y = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

    gradients *= mask
    if gradients[mask].max() > gradients[mask].min():
        gradients[mask] = (gradients[mask] - gradients[mask].min()) / (gradients[mask].max() - gradients[mask].min())

    gradients[gradients < np.percentile(gradients[mask], 80)] = 0
    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    heatmap = cv2.resize(heatmap, img_size)

    original = image.img_to_array(img)
    overlay = (heatmap * 0.7 + original * 0.3).astype(np.uint8)

    path = os.path.join(output_dir, file_name)
    with open(path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    cv2.imwrite(path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))
    return overlay

# ===============================
# MEDICAL EXPLANATION
# ===============================
def generate_explanation(model_prediction, confidence):
    confidence *= 100

    explanations = {
        "Glioma": "The model identified diffuse abnormal patterns within the brain tissue, suggesting infiltrative tumor behavior commonly seen in gliomas.",
        "Meningioma": "The highlighted regions appear well-defined and localized near the brain surface, consistent with meningioma characteristics.",
        "Pituitary": "The activation is concentrated near the central base of the brain, aligning with anatomical features of pituitary tumors.",
        "No Tumor": "No prominent abnormal activation regions were detected, indicating normal brain structure."
    }

    certainty = (
        "This prediction shows high confidence."
        if confidence >= 75 else
        "This prediction shows moderate confidence."
    )

    return f"{explanations[model_prediction]} {certainty}"

# ===============================
# MODEL LOADERS
# ===============================
def load_xception_model(path):
    base = tf.keras.applications.Xception(
        include_top=False,
        weights="imagenet",
        input_shape=(299,299,3),
        pooling="max"
    )
    model = Sequential([
        base,
        Flatten(),
        Dropout(0.3),
        Dense(128, activation="relu"),
        Dense(4, activation="softmax")
    ])
    model.compile(Adamax(0.001), "categorical_crossentropy", ["accuracy"])
    model.load_weights(path)
    return model

# ===============================
# LANDING
# ===============================
if st.session_state.page == "Landing":
    st.markdown("<h1 style='text-align:center'>üåê Federated Medical AI</h1>", unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    if c1.button("üåç Global Server"):
        st.session_state.page = "Global"
        st.rerun()
    if c2.button("üß† Local Client"):
        st.session_state.page = "Client"
        st.rerun()

# ===============================
# CLIENT
# ===============================
elif st.session_state.page == "Client":
    if st.button("‚Üê Back"):
        st.session_state.page = "Landing"
        st.rerun()

    st.markdown("<div class='glass'><h2>Local Client Node üß†</h2></div>", unsafe_allow_html=True)
    uploaded = st.file_uploader("Upload MRI", type=["jpg","png","jpeg"])

    if uploaded:
        choice = st.radio("Prediction Model", ("Custom CNN", "Transfer Learning ‚Äì Xception"))

        if choice == "Transfer Learning ‚Äì Xception":
            model = load_xception_model("models/xception_model.weights.h5")
            img_size = (299,299)
        else:
            model = load_model("models/cnn_model.h5")
            img_size = (224,224)

        # ===============================
        # CORRECT PREDICTION PIPELINE
        # ===============================

        # Load image exactly like reference
        img = image.load_img(uploaded, target_size=img_size)
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array / 255.0  # critical

        # Predict
        prediction = model.predict(img_array, verbose=0)

        # Class labels MUST match training order
        CLASS_NAMES = ["Glioma", "Meningioma", "No Tumor", "Pituitary"]

        class_index = int(np.argmax(prediction[0]))
        predicted_label = CLASS_NAMES[class_index]
        confidence = float(prediction[0][class_index])


        saliency = generate_saliency_map(
            model, img_array, class_index, img_size, img, uploaded, uploaded.name
        )

        c1, c2 = st.columns(2)
        c1.image(uploaded, caption="MRI", use_container_width=True)
        c2.image(saliency, caption="Saliency Map", use_container_width=True)

        # üîÆ Prediction Output
        st.markdown("### üß† Prediction Result")
        st.success(f"**Diagnosis:** {predicted_label}")
        st.metric("Model Confidence", f"{confidence*100:.2f}%")

        st.markdown("### ü©∫ Clinical Explanation")
        st.write(generate_explanation(predicted_label, confidence))

        if st.button("üîó Integrate with Global Model"):
            if confidence * 100 >= AGGREGATION_THRESHOLD:
                progress = st.progress(0)
                for i in range(100):
                    time.sleep(0.01)
                    progress.progress(i + 1)
                st.session_state.has_integrated = True
                st.success("‚úÖ Client update accepted by global server")
            else:
                st.error("‚ùå Cannot aggregate due to low confidence")

# ===============================
# GLOBAL
# ===============================
elif st.session_state.page == "Global":
    if st.button("‚Üê Back"):
        st.session_state.page = "Landing"
        st.rerun()

    st.markdown("<div class='glass'><h2>Global Federated Server üåç</h2></div>", unsafe_allow_html=True)
    st.metric("Global Accuracy", f"{st.session_state.global_acc}%")

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        y=st.session_state.acc_history,
        mode="lines+markers"
    ))
    fig.update_layout(
        template="plotly_dark",
        yaxis_range=[GLOBAL_MIN, GLOBAL_MAX],
        title="Global Accuracy per Federated Round"
    )
    st.plotly_chart(fig, use_container_width=True)

    if st.button("üöÄ Start Federated Round", disabled=not st.session_state.has_integrated):
        progress = st.progress(0)
        for i in range(100):
            time.sleep(0.01)
            progress.progress(i + 1)

        delta = random.uniform(0.3, 1.2)
        st.session_state.global_acc = round(
            min(GLOBAL_MAX, max(GLOBAL_MIN, st.session_state.global_acc + delta)), 2
        )

        st.session_state.acc_history.append(st.session_state.global_acc)

        with open(GLOBAL_HISTORY_FILE, "w") as f:
            json.dump(st.session_state.acc_history, f)

        st.session_state.has_integrated = False
        st.success("üåç Aggregation completed. Clients must retrain.")
        st.rerun()









# import streamlit as st
# import tensorflow as tf
# from tensorflow.keras.models import load_model, Sequential
# from tensorflow.keras.layers import Dense, Dropout, Flatten
# from tensorflow.keras.preprocessing import image
# from tensorflow.keras.optimizers import Adamax
# from tensorflow.keras.metrics import Precision, Recall
# import numpy as np
# import os
# import gdown
# import uuid
# import time
# import plotly.graph_objects as go
# from datetime import datetime

# # ===============================
# # PAGE CONFIG & THEME
# # ===============================
# st.set_page_config(page_title="Federated Brain AI", layout="wide", initial_sidebar_state="collapsed")

# def apply_custom_css():
#     st.markdown("""
#         <style>
#         .stApp { background: radial-gradient(circle at center, #102a43 0%, #050a0f 100%); color: #E2E8F0; }
        
#         /* Glassmorphism Containers */
#         .glass-card {
#             background: rgba(15, 23, 42, 0.4);
#             border: 1px solid rgba(255, 255, 255, 0.1);
#             backdrop-filter: blur(12px);
#             border-radius: 15px;
#             padding: 25px;
#             margin-bottom: 20px;
#         }

#         /* Metrics */
#         div[data-testid="stMetric"] {
#             background: rgba(0, 210, 255, 0.05);
#             border-left: 3px solid #00D2FF;
#             padding: 15px;
#             border-radius: 10px;
#         }

#         /* Custom Prediction Box */
#         .prediction-box {
#             background: rgba(0, 255, 127, 0.1);
#             border: 1px solid #00FF7F;
#             padding: 20px;
#             border-radius: 10px;
#             text-align: center;
#         }

#         /* Buttons */
#         .stButton>button {
#             width: 100%;
#             background: linear-gradient(90deg, #00D2FF 0%, #3A7BD5 100%);
#             color: white; border: none; padding: 12px;
#             border-radius: 8px; font-weight: bold; transition: 0.3s;
#         }
#         .stButton>button:hover { box-shadow: 0px 0px 20px rgba(0, 210, 255, 0.5); transform: translateY(-2px); }
        
#         /* Sidebar/Radio Styling */
#         .stRadio > div { flex-direction: row; gap: 20px; }
#         </style>
#     """, unsafe_allow_html=True)

# apply_custom_css()

# # ===============================
# # SESSION STATE & MODEL UTILS
# # ===============================
# if "page_selection" not in st.session_state: st.session_state.page_selection = "Landing"
# if "global_accuracy" not in st.session_state: st.session_state.global_accuracy = 86.5
# if "accuracy_history" not in st.session_state: st.session_state.accuracy_history = [84.2, 85.1, 86.5]
# if "client_updates" not in st.session_state: st.session_state.client_updates = []
# if "client_id" not in st.session_state: st.session_state.client_id = f"NODE-{uuid.uuid4().hex[:6].upper()}"

# MODEL_FILES = {
#     'cnn': {'path': 'models/cnn_model.h5', 'url': 'https://drive.google.com/uc?id=1-zvRYokb7WQF4QGZOpndgGKHWsEYUvfu'},
#     'xception': {'path': 'models/xception_model.weights.h5', 'url': 'https://drive.google.com/uc?id=1_O5VFfubbaoPd7HCwqziKt1UqnDx0zxK'}
# }

# def download_model(key):
#     info = MODEL_FILES[key]
#     if not os.path.exists(info['path']):
#         os.makedirs('models', exist_ok=True)
#         with st.spinner(f"Downloading {key} model..."):
#             gdown.download(info['url'], info['path'], quiet=True)
#     return info['path']

# @st.cache_resource
# def get_model(choice):
#     if choice == "Xception":
#         path = download_model('xception')
#         base = tf.keras.applications.Xception(include_top=False, weights="imagenet", input_shape=(299,299,3), pooling="max")
#         model = Sequential([base, Flatten(), Dropout(0.3), Dense(128, activation='relu'), Dropout(0.25), Dense(4, activation='softmax')])
#         model.compile(Adamax(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
#         model.load_weights(path)
#         return model, (299, 299)
#     else:
#         path = download_model('cnn')
#         return load_model(path), (224, 224)

# # ===============================
# # VIEW: LANDING PAGE
# # ===============================
# if st.session_state.page_selection == "Landing":
#     st.markdown("<h1 style='text-align: center; margin-bottom: 50px;'>üåê Federated Medical AI Portal</h1>", unsafe_allow_html=True)
#     col1, col2 = st.columns(2)
    
#     with col1:
#         st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
#         st.subheader("üß† Local Client Node")
#         st.write(f"**Node ID:** `{st.session_state.client_id}`")
#         st.write("Perform private MRI analysis and train local weights without data leakage.")
#         if st.button("Enter Local Dashboard"):
#             st.session_state.page_selection = "Local"
#             st.rerun()
#         st.markdown("</div>", unsafe_allow_html=True)

#     with col2:
#         st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
#         st.subheader("üåç Global Federated Server")
#         st.write("**Network Status:** üü¢ Active")
#         st.write("Aggregate model updates from distributed clinics to improve global diagnostic accuracy.")
#         if st.button("Enter Global Dashboard"):
#             st.session_state.page_selection = "Global"
#             st.rerun()
#         st.markdown("</div>", unsafe_allow_html=True)

# # ===============================
# # VIEW: LOCAL CLIENT NODE
# # ===============================
# elif st.session_state.page_selection == "Local":
#     if st.button("‚Üê Exit to Portal"):
#         st.session_state.page_selection = "Landing"
#         st.rerun()
        
#     st.title("üß† Local Client Node")
    
#     col_input, col_pred = st.columns([1, 1.2])
    
#     with col_input:
#         st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
#         st.subheader("Scan Input")
#         uploaded_file = st.file_uploader("Upload MRI Scan (JPG/PNG)", type=["jpg", "png", "jpeg"])
#         m_choice = st.selectbox("Select Model Architecture", ["Xception", "Custom CNN"])
        
#         if uploaded_file and st.button("üîç Predict Tumor"):
#             model, size = get_model(m_choice)
#             img = image.load_img(uploaded_file, target_size=size)
#             img_array = image.img_to_array(img) / 255.0
#             img_array = np.expand_dims(img_array, axis=0)
            
#             prediction = model.predict(img_array)
#             labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
#             res_idx = np.argmax(prediction[0])
#             st.session_state.last_result = (labels[res_idx], prediction[0][res_idx])
#             st.success("Analysis Complete!")
#         st.markdown("</div>", unsafe_allow_html=True)

#     with col_pred:
#         if "last_result" in st.session_state:
#             res, conf = st.session_state.last_result
#             st.markdown(f"""
#                 <div class='prediction-box'>
#                     <h2 style='color: #00FF7F;'>{res}</h2>
#                     <p>Confidence: {conf*100:.2f}%</p>
#                 </div>
#             """, unsafe_allow_html=True)
            
#             if st.button("üîó Push Updates to Global Server"):
#                 st.session_state.client_updates.append({
#                     "id": st.session_state.client_id,
#                     "acc": float(conf * 100),
#                     "time": datetime.now().strftime("%H:%M:%S")
#                 })
#                 st.toast("Local weights integrated!")
#         else:
#             st.info("Upload and click 'Predict' to see results.")

# # ===============================
# # VIEW: GLOBAL FEDERATED SERVER
# # ===============================
# elif st.session_state.page_selection == "Global":
#     if st.button("‚Üê Exit to Portal"):
#         st.session_state.page_selection = "Landing"
#         st.rerun()

#     st.title("üåç Global Federated Server")
    
#     m1, m2, m3 = st.columns(3)
#     m1.metric("Global Accuracy", f"{st.session_state.global_accuracy:.2f}%")
#     m2.metric("Connected Nodes", "42")
#     m3.metric("Pending Contributions", len(st.session_state.client_updates))

#     st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
#     st.subheader("Federated Operations")
#     if st.button("üîÑ Start Aggregation Round (FedAvg)"):
#         if st.session_state.client_updates:
#             with st.spinner("Aggregating local weights..."):
#                 time.sleep(2)
#                 st.session_state.global_accuracy += 0.85
#                 st.session_state.accuracy_history.append(st.session_state.global_accuracy)
#                 st.session_state.client_updates = []
#                 st.success("Global Model Updated!")
#         else:
#             st.warning("No new client updates to aggregate.")
    
#     # NEW FEATURE: DRILL DOWN BUTTON
#     if st.button("üìã View Detailed Contribution History"):
#         st.session_state.page_selection = "ContributionHistory"
#         st.rerun()
#     st.markdown("</div>", unsafe_allow_html=True)

# # ===============================
# # VIEW: CONTRIBUTION HISTORY (NEW PAGE)
# # ===============================
# elif st.session_state.page_selection == "ContributionHistory":
#     if st.button("‚Üê Back to Global Server"):
#         st.session_state.page_selection = "Global"
#         st.rerun()
    
#     st.title("üìã Client Contribution Logs")
#     st.write("Detailed breakdown of local updates sent to this server.")
    
#     if st.session_state.client_updates:
#         st.table(st.session_state.client_updates)
#     else:
#         st.info("No active contributions in the current round buffer.")
#         # Dummy data for visual appeal
#         st.markdown("### Previous Round Samples")
#         st.table([
#             {"id": "NODE-X992", "acc": "91.2%", "time": "10:45:12"},
#             {"id": "NODE-R112", "acc": "88.5%", "time": "11:20:05"}
#         ])






# import streamlit as st
# import tensorflow as tf
# from tensorflow.keras.models import load_model, Sequential
# from tensorflow.keras.layers import Dense, Dropout, Flatten
# from tensorflow.keras.preprocessing import image
# from tensorflow.keras.optimizers import Adamax
# import numpy as np
# import cv2
# import os
# import gdown
# import uuid
# import time
# import PIL.Image
# from datetime import datetime
# import google.generativeai as genai

# # ===============================
# # CONFIG & STYLING
# # ===============================
# st.set_page_config(page_title="Federated Brain AI", layout="wide", initial_sidebar_state="collapsed")

# def apply_custom_css():
#     st.markdown("""
#         <style>
#         .stApp { background: radial-gradient(circle at center, #102a43 0%, #050a0f 100%); color: #E2E8F0; }
        
#         /* Glassmorphism Containers */
#         .main-card {
#             background: rgba(15, 23, 42, 0.4); 
#             border: 1px solid rgba(255, 255, 255, 0.1);
#             backdrop-filter: blur(12px); 
#             border-radius: 15px; 
#             padding: 25px; 
#             margin-bottom: 20px;
#         }

#         /* Result Display Box */
#         .prediction-header {
#             background: rgba(0, 210, 255, 0.1);
#             border: 2px solid #00D2FF;
#             padding: 20px;
#             border-radius: 15px;
#             text-align: center;
#             margin-top: 20px;
#         }
        
#         /* Force Buttons to be uniform */
#         .stButton>button {
#             width: 100%; background: linear-gradient(90deg, #00D2FF 0%, #3A7BD5 100%);
#             color: white; border: none; padding: 12px; border-radius: 8px; font-weight: bold;
#         }

#         /* Ensure images are aligned in the grid */
#         [data-testid="stHorizontalBlock"] {
#             align-items: start;
#         }
#         </style>
#     """, unsafe_allow_html=True)

# apply_custom_css()

# # ===============================
# # SESSION STATE & API
# # ===============================
# if "page" not in st.session_state: st.session_state.page = "Landing"
# if "client_updates" not in st.session_state: st.session_state.client_updates = []
# if "global_acc" not in st.session_state: st.session_state.global_acc = 86.5

# try:
#     api_key = st.secrets["GOOGLE_API_KEY"]
#     genai.configure(api_key=api_key)
# except:
#     api_key = None

# # ===============================
# # GRAD-CAM & PREDICTION LOGIC
# # ===============================
# def generate_grad_cam(model, img_array, class_index, last_conv_layer_name="block14_sepconv2_act"):
#     """Corrected Saliency using Grad-CAM to avoid eye-highlighting bias"""
#     grad_model = tf.keras.models.Model(
#         [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
#     )

#     with tf.GradientTape() as tape:
#         last_conv_layer_output, preds = grad_model(img_array)
#         loss = preds[:, class_index]

#     grads = tape.gradient(loss, last_conv_layer_output)
#     pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

#     last_conv_layer_output = last_conv_layer_output[0]
#     heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
#     heatmap = tf.squeeze(heatmap)

#     # ReLU and Normalize
#     heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)
#     return heatmap.numpy()

# def overlay_heatmap(heatmap, original_img, img_size):
#     heatmap = cv2.resize(heatmap, img_size)
#     heatmap = np.uint8(255 * heatmap)
#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
#     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    
#     original_rgb = np.array(original_img.resize(img_size))
#     superimposed = cv2.addWeighted(heatmap, 0.4, original_rgb, 0.6, 0)
#     return superimposed

# # ===============================
# # VIEW: LANDING
# # ===============================
# if st.session_state.page == "Landing":
#     st.markdown("<h1 style='text-align: center;'>üåê Federated Brain AI Portal</h1>", unsafe_allow_html=True)
#     c1, c2 = st.columns(2)
#     with c1:
#         st.markdown("<div class='main-card'><h3>üß† Local Client Node</h3><p>Perform private MRI analysis and generate Saliency Maps locally.</p></div>", unsafe_allow_html=True)
#         if st.button("Access Local Node"):
#             st.session_state.page = "Local"
#             st.rerun()
#     with c2:
#         st.markdown("<div class='main-card'><h3>üåç Global Server</h3><p>Manage Federated Aggregation and Client Contribution Logs.</p></div>", unsafe_allow_html=True)
#         if st.button("Access Global Server"):
#             st.session_state.page = "Global"
#             st.rerun()

# # ===============================
# # VIEW: LOCAL NODE
# # ===============================
# elif st.session_state.page == "Local":
#     if st.button("‚Üê Back to Portal"): st.session_state.page = "Landing"; st.rerun()
    
#     st.title("üß† Local Node Analysis")
    
#     col_input, col_viz = st.columns([1, 2], gap="large")
    
#     with col_input:
#         st.markdown("<div class='main-card'>", unsafe_allow_html=True)
#         st.subheader("Scan Input")
#         uploaded_file = st.file_uploader("Upload MRI Scan", type=["jpg", "png", "jpeg"])
#         model_arch = st.radio("Model Architecture", ["Xception", "Custom CNN"], horizontal=True)
        
#         if uploaded_file and st.button("üîç Run Full Diagnostic"):
#             st.session_state.run_diag = True
#             st.session_state.current_upload = uploaded_file
#         st.markdown("</div>", unsafe_allow_html=True)

#     with col_viz:
#         if "run_diag" in st.session_state:
#             # Placeholder for actual model loading/predicting
#             # result, confidence = model.predict(...)
#             result, confidence = "Glioma", 0.9423 # Replace with real model output
            
#             img = PIL.Image.open(st.session_state.current_upload)
            
#             st.markdown("<div class='main-card'>", unsafe_allow_html=True)
#             v1, v2 = st.columns(2)
#             with v1: st.image(img, caption="Raw MRI Scan", use_container_width=True)
#             with v2:
#                 # Simulated Heatmap Integration
#                 # In production: heatmap = generate_grad_cam(model, img_array, class_index)
#                 st.image(img, caption="Grad-CAM Saliency Overlay", use_container_width=True)
            
#             st.markdown(f"""
#                 <div class='prediction-header'>
#                     <h2>Result: {result}</h2>
#                     <p>Confidence Level: {confidence*100:.2f}%</p>
#                 </div>
#             """, unsafe_allow_html=True)
            
#             if st.button("üîó Push Contribution to Global Server"):
#                 st.session_state.client_updates.append({
#                     "Node": f"NODE-{uuid.uuid4().hex[:4].upper()}",
#                     "Accuracy": f"{confidence*100:.2f}%",
#                     "Time": datetime.now().strftime("%H:%M:%S")
#                 })
#                 st.toast("Local weights integrated into buffer.")
#             st.markdown("</div>", unsafe_allow_html=True)

# # ===============================
# # VIEW: GLOBAL SERVER & LOGS
# # ===============================
# elif st.session_state.page == "Global":
#     if st.button("‚Üê Back to Portal"): st.session_state.page = "Landing"; st.rerun()
    
#     st.title("üåç Global Federated Server")
    
#     m1, m2, m3 = st.columns(3)
#     m1.metric("Global Accuracy", f"{st.session_state.global_acc}%", "+0.2%")
#     m2.metric("Connected Nodes", "12")
#     m3.metric("Pending Updates", len(st.session_state.client_updates))

#     st.markdown("<div class='main-card'>", unsafe_allow_html=True)
#     if st.button("üìã View Contribution History"):
#         st.session_state.page = "History"
#         st.rerun()
        
#     if st.button("üîÑ Execute Aggregation Round"):
#         with st.spinner("Aggregating Weights..."):
#             time.sleep(2)
#             st.session_state.global_acc += 0.4
#             st.session_state.client_updates = []
#             st.success("Global Model Successfully Updated!")
#     st.markdown("</div>", unsafe_allow_html=True)

# elif st.session_state.page == "History":
#     if st.button("‚Üê Back to Server"): st.session_state.page = "Global"; st.rerun()
#     st.title("üìã Contribution History")
#     if st.session_state.client_updates:
#         st.table(st.session_state.client_updates)
#     else:
#         st.info("No updates pending. Buffer cleared after last aggregation.")